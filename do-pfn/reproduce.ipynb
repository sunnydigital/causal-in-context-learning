{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.transformer_prediction_interface.base import DoPFNRegressor\n",
    "import torch\n",
    "from dowhy import gcm\n",
    "from dowhy.gcm.auto import AssignmentQuality\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datasets import load_dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference:   0%|          | 0/1 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dlclarge1/robertsj-dopfn/Do-PFN/scripts/transformer_prediction_interface/base.py:1497: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.fp16_inference):\n",
      "Running inference: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\n",
      "Running inference:   0%|          | 0/1 [00:00<?, ?batch/s]/work/dlclarge1/robertsj-dopfn/Do-PFN/scripts/transformer_prediction_interface/base.py:1497: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.fp16_inference):\n",
      "Running inference: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(ds_name=\"sales_cate\")\n",
    "\n",
    "dopfn = DoPFNRegressor()\n",
    "\n",
    "train_ds, test_ds = dataset.generate_valid_split(n_splits=5)\n",
    "\n",
    "dopfn.fit(train_ds.x_obs, train_ds.y_obs)\n",
    "\n",
    "y_1_pred = dopfn.predict(test_ds.x)\n",
    "\n",
    "test_ds.x[:, 0] = test_ds.x_obs[:, 0] # contains the opposite treatments {t=1 if 0, else t=0}\n",
    "\n",
    "y_0_pred = dopfn.predict(test_ds.x)\n",
    "\n",
    "cate_pred = y_1_pred - y_0_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting causal mechanism of node Operational Cost: 100%|██████████| 8/8 [00:00<00:00, 52.88it/s]\n"
     ]
    }
   ],
   "source": [
    "graph = train_ds.function_args['graph']\n",
    "\n",
    "graph_nodes = deepcopy(graph.nodes)\n",
    "for node in graph_nodes:\n",
    "    if node not in train_ds.attribute_names:\n",
    "        graph.remove_node(node)\n",
    "\n",
    "causal_model = gcm.InvertibleStructuralCausalModel(graph)\n",
    "\n",
    "train_df = pd.DataFrame(torch.concat([train_ds.x, train_ds.y.unsqueeze(1)], axis=1), columns=train_ds.attribute_names)\n",
    "test_df = pd.DataFrame(torch.concat([test_ds.x_obs, test_ds.y_obs.unsqueeze(1)], axis=1), columns=test_ds.attribute_names)\n",
    "\n",
    "gcm.auto.assign_causal_mechanisms(causal_model, train_df, AssignmentQuality.BETTER)\n",
    "gcm.fit(causal_model, train_df)\n",
    "\n",
    "samples_1 = gcm.counterfactual_samples(\n",
    "    interventions={test_ds.do_scm.scm.t_key: lambda x: test_ds.x_int[:, 0].numpy()},\n",
    "    causal_model=causal_model,\n",
    "    observed_data=test_df\n",
    ")\n",
    "\n",
    "samples_0 = gcm.counterfactual_samples(\n",
    "    interventions={test_ds.do_scm.scm.t_key: lambda x: test_ds.x_obs[:, 0].numpy()},\n",
    "    causal_model=causal_model, \n",
    "    observed_data=test_df\n",
    ")\n",
    "\n",
    "cate_true = samples_1[test_ds.do_scm.scm.y_key].values - samples_0[test_ds.do_scm.scm.y_key].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/latex": [
       "$\\displaystyle 0.0310735652495692$"
      ],
      "text/plain": [
       "0.03107356524956924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n_mse(pred, true):\n",
    "    return (((pred - true) / (true.max() - true.min())) ** 2).mean()\n",
    "\n",
    "n_mse(cate_pred, cate_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACIC 2016 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ACIC 2016 challenge dataset\n",
    "#\n",
    "# Sources:\n",
    "# [1] Dorie, Vincent, et al. \"Automated versus do-it-yourself methods for causal inference: Lessons learned\n",
    "# from a data analysis competition.\" (2019): 43-68.\n",
    "# [2] https://github.com/BiomedSciAI/causallib/tree/master/causallib/datasets/data/acic_challenge_2016\n",
    "#\n",
    "# The challenge includes 10 different datasets.\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CATE_Dataset:  # conditional average treatment effect\n",
    "    X_train: np.ndarray\n",
    "    t_train: np.ndarray\n",
    "    y_train: np.ndarray\n",
    "    X_test: np.ndarray\n",
    "    true_cate: np.ndarray\n",
    "\n",
    "\n",
    "class EvalDatasetCatalog(ABC):\n",
    "    \"\"\"\n",
    "    The dataset catalog is a collection of datasets used for evaluating the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_tables: int, name: str):\n",
    "        self.n_tables = n_tables\n",
    "        self.name = name\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_tables\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    @abstractmethod\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        raise NotImplementedError(\"This method should be implemented by the subclass\")\n",
    "\n",
    "\n",
    "X_CSV_URL = (\n",
    "    \"https://raw.githubusercontent.com/BiomedSciAI/causallib/master/causallib/datasets/data/acic_challenge_2016/x.csv\"\n",
    ")\n",
    "\n",
    "ZY_CSV_URL = (\n",
    "    lambda i: f\"https://raw.githubusercontent.com/BiomedSciAI/causallib/master/causallib/datasets/data/acic_challenge_2016/zymu_{i}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "class ACIC2016Dataset(EvalDatasetCatalog):\n",
    "    def __init__(self, test_ratio: float = 0.1, seed: int = 42, n_tables: int = 10):\n",
    "        super().__init__(n_tables, name=\"ACIC2016\")\n",
    "        self.test_ratio = test_ratio\n",
    "        self.x_data = pd.read_csv(X_CSV_URL)\n",
    "        self.rngs = [np.random.default_rng(seed + i) for i in range(n_tables)]\n",
    "        self.datasets = [self._get_data(i) for i in range(n_tables)]\n",
    "\n",
    "    def _get_data(self, idx: int) -> CATE_Dataset:\n",
    "        \"\"\"Loads and processes a single dataset split.\"\"\"\n",
    "        # Download file URLs\n",
    "        simulation_url = ZY_CSV_URL(idx + 1)\n",
    "\n",
    "        sim_data = pd.read_csv(simulation_url)\n",
    "\n",
    "        # Define column names for x.csv and simulation data\n",
    "        self.x_data.columns = [f\"x_{i+1}\" for i in range(self.x_data.shape[1])]\n",
    "        sim_data.columns = [\"z\", \"y0\", \"y1\", \"mu0\", \"mu1\"]\n",
    "\n",
    "        # Handle categorical variables\n",
    "        categorical_columns = [\"x_2\", \"x_21\", \"x_24\"]\n",
    "        numerical_columns = [f\"x_{i+1}\" for i in range(self.x_data.shape[1]) if f\"x_{i+1}\" not in categorical_columns]\n",
    "        self.x_data[\"x_2_numeric\"] = self.x_data[\"x_2\"].astype(\"category\").cat.codes\n",
    "        self.x_data[\"x_21_numeric\"] = self.x_data[\"x_21\"].astype(\"category\").cat.codes\n",
    "        self.x_data[\"x_24_numeric\"] = self.x_data[\"x_24\"].astype(\"category\").cat.codes\n",
    "        numerical_columns = numerical_columns + [\"x_2_numeric\", \"x_21_numeric\", \"x_24_numeric\"]\n",
    "        self.x_data = self.x_data.loc[:, numerical_columns]\n",
    "\n",
    "        # Convert to tensors\n",
    "        covariates = self.x_data.values.astype(np.float32)  # Covariates with encoded categorical variables\n",
    "        treatments = sim_data[\"z\"].values.astype(np.float32)  # Treatment\n",
    "\n",
    "        y1 = sim_data[\"y1\"].values.astype(np.float32)  # Potential outcomes under treatment\n",
    "        y0 = sim_data[\"y0\"].values.astype(np.float32)  # Potential outcomes under control\n",
    "        outcomes = np.where(treatments == 1, y1, y0)\n",
    "\n",
    "        mu0 = sim_data[\"mu0\"].values.astype(np.float32)\n",
    "        mu1 = sim_data[\"mu1\"].values.astype(np.float32)\n",
    "        cate = mu1 - mu0\n",
    "\n",
    "        # Split the dataset into train and test sets\n",
    "        indices = self.rngs[idx].permutation(covariates.shape[0])\n",
    "        split_idx = int(len(indices) * (1 - self.test_ratio))\n",
    "        train_indices = indices[:split_idx]\n",
    "        test_indices = indices[split_idx:]\n",
    "        cate_dataset = CATE_Dataset(\n",
    "            X_train=covariates[train_indices],\n",
    "            t_train=treatments[train_indices],\n",
    "            y_train=outcomes[train_indices],\n",
    "            X_test=covariates[test_indices],\n",
    "            true_cate=cate[test_indices],\n",
    "        )\n",
    "\n",
    "        return cate_dataset\n",
    "\n",
    "    def __getitem__(self, index) -> CATE_Dataset:\n",
    "        return self.datasets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.95s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.17s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.12s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.96s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.05s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:10<00:00, 10.27s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:08<00:00,  8.20s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.88s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.08s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.92s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.51s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.43s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.87s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.41s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.33s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.84s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:05<00:00,  5.16s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.78s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.73s/batch]\n",
      "Running inference: 100%|██████████| 1/1 [00:04<00:00,  4.69s/batch]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "dataset = ACIC2016Dataset()\n",
    "\n",
    "pehes = []\n",
    "for i in range(len(dataset)):\n",
    "    cate_dset: CATE_Dataset = dataset[i]\n",
    "    X_train = cate_dset.X_train\n",
    "    t_train = cate_dset.t_train\n",
    "    X_t_train = np.concatenate(\n",
    "        [t_train[:, None], X_train],\n",
    "        axis=1,\n",
    "    )\n",
    "    dopfn = DoPFNRegressor()\n",
    "    dopfn.fit(X_t_train, cate_dset.y_train)\n",
    "\n",
    "    x_1, x_0 = deepcopy(cate_dset.X_test), deepcopy(cate_dset.X_test)\n",
    "    X_test_0 = np.concatenate(\n",
    "        [\n",
    "            np.zeros((x_0.shape[0], 1)),\n",
    "            x_0,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    X_test_1 = np.concatenate(\n",
    "        [\n",
    "            np.ones((x_1.shape[0], 1)),\n",
    "            x_1,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    y_test_0 = dopfn.predict(torch.from_numpy(X_test_0))\n",
    "    y_test_1 = dopfn.predict(torch.from_numpy(X_test_1))\n",
    "    cate_pred = y_test_1 - y_test_0\n",
    "    pehe = np.sqrt(np.mean((cate_pred - cate_dset.true_cate) ** 2))\n",
    "    pehes.append(pehe)\n",
    "\n",
    "avg_pehe = sum(pehes) / len(pehes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PEHE over 10 datasets: 4.8290\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average PEHE over {len(dataset)} datasets: {avg_pehe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prior-fitting-24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
